---
---

@inproceedings{kang2022tactileloc,
  abbr={IJCNN},
  bibtex_show={true},
  title={Event-driven Tactile Learning with Location Spiking Neurons},
  author={Kang, Peng and Banerjee, Srutarshi and Chopp, Henry and Katsaggelos, Aggelos and Cossairt, Oliver},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2022},
  organization={IEEE},
  selected={true}
}

@inproceedings{kang2021human,
  abbr={ICIP},
  bibtex_show={true},
  title={Human Vision-Like Robust Object Recognition},
  abstract={Previous research always solely utilizes Artificial Neural Networks (ANNs) or Spiking Neural Networks (SNNs) for object recognition. However, evidence in neuroscience suggests that the visual processing in human vision is performed hierarchically in the combination of analog and digital processing. To construct a more human vision-like object recognition system, we propose a general hierarchical ANN-SNN model. We evaluate our model and its variants on two popular datasets to show its effectiveness, robustness, efficiency, and generality. Extensive experiments clearly demonstrate the superiority of our proposed models for robust object recognition.},
  author={Kang, Peng and Hu, Hao and Banerjee, Srutarshi and Chopp, Henry and Katsaggelos, Aggelos and Cossairt, Oliver},
  booktitle={2021 IEEE International Conference on Image Processing (ICIP)},
  pages={709--713},
  year={2021},
  organization={IEEE}
}

@inproceedings{kang2021atm,
  abbr={WACV},
  bibtex_show={true},
  title={ATM: Attentional text matting},
  author={Kang, Peng and Zhang, Jianping and Ma, Chen and Sun, Guiling},
  abstract={Image matting is a fundamental computer vision problem and has many applications. Previous image matting methods always focus on extracting a general object or portrait from the background in an image. In this paper, we try to solve the text matting problem, which extracts characters (usually WordArts) from the background in an image. Different from traditional image matting problems, text matting is much harder because of its foreground's three properties: smallness, multi-objectness, and complicated structures and boundaries. We propose a two-stage attentional text matting pipeline to solve the text matting problem. In the first stage, we utilize text detection methods to serve as the attention mechanism. In the second stage, we employ the attentional text regions and matting system to obtain mattes of these text regions. Finally, we post-process the mattes and obtain the final matte of the input image. We also construct a large-scale dataset with high-quality annotations consisting of 46,289 unique foregrounds to facilitate the learning and evaluation of text matting. Extensive experiments on this dataset and real images clearly demonstrate the superiority of our proposed pipeline over previous image matting methods on the task of text matting.},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3902--3911},
  year={2021}
}

@article{chang2020error,
  bibtex_show={true},
  title={Error bounds for computed least squares estimators},
  author={Chang, Xiao-Wen and Kang, Peng and Titley-Peloquin, David},
  abstract={This paper is concerned with normwise errors in the LS estimation for linear regression. It provides probabilistic tail bounds for the normwise error between the computed least squares estimator and the parameter vector, when the least squares problem is solved in floating point arithmetic using either the normal equations method or a backward stable method (for example, using the Householder QR factorization or the singular value decomposition). These bounds are used to provide a condition under which the computationally more efficient normal equations method can safely be used instead of a backward stable method, without any loss of accuracy in the computed estimator.},
  journal={Linear Algebra and its Applications},
  volume={586},
  pages={28--42},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{ma2019hierarchical,
  abbr={KDD},
  bibtex_show={true},
  title={Hierarchical gating networks for sequential recommendation},
  author={Ma, Chen and Kang, Peng and Liu, Xue},
  abstract={The chronological order of user-item interactions is a key feature in many recommender systems, where the items that users will interact may largely depend on those items that users just accessed recently. However, with the tremendous increase of users and items, sequential recommender systems still face several challenging problems: (1) the hardness of modeling the long-term user interests from sparse implicit feedback; (2) the difficulty of capturing the short-term user interests given several items the user just accessed. To cope with these challenges, we propose a hierarchical gating network (HGN), integrated with the Bayesian Personalized Ranking (BPR) to capture both the long-term and short-term user interests. Our HGN consists of a feature gating module, an instance gating module, and an item-item product module. In particular, our feature gating and instance gating modules select what item features can be passed to the downstream layers from the feature and instance levels, respectively. Our item-item product module explicitly captures the item relations between the items that users accessed in the past and those items users will access in the future. We extensively evaluate our model with several state-of-the-art methods and different validation metrics on five real-world datasets. The experimental results demonstrate the effectiveness of our model on Top-N sequential recommendation.},
  booktitle={Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery \& data mining},
  pages={825--833},
  year={2019},
  selected={true}
}

@inproceedings{ma2019gated,
  abbr={WSDM},
  bibtex_show={true},
  title={Gated attentive-autoencoder for content-aware recommendation},
  author={Ma, Chen and Kang, Peng and Wu, Bin and Wang, Qinglong and Liu, Xue},
  abstract={The rapid growth of Internet services and mobile devices provides an excellent opportunity to satisfy the strong demand for the personalized item or product recommendation. However, with the tremendous increase of users and items, personalized recommender systems still face several challenging problems: (1) the hardness of exploiting sparse implicit feedback; (2) the difficulty of combining heterogeneous data. To cope with these challenges, we propose a gated attentive-autoencoder (GATE) model, which is capable of learning fused hidden representations of items' contents and binary ratings, through a neural gating structure. Based on the fused representations, our model exploits neighboring relations between items to help infer users' preferences. In particular, a word-level and a neighbor-level attention module are integrated with the autoencoder. The word-level attention learns the item hidden representations from items' word sequences, while favoring informative words by assigning larger attention weights. The neighbor-level attention learns the hidden representation of an item's neighborhood by considering its neighbors in a weighted manner. We extensively evaluate our model with several state-of-the-art methods and different validation metrics on four real-world datasets. The experimental results not only demonstrate the effectiveness of our model on top-N recommendation but also provide interpretable results attributed to the attention modules.},
  booktitle={Proceedings of the twelfth ACM international conference on web search and data mining},
  pages={519--527},
  year={2019}
}


